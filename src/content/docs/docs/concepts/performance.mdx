---
title: Performance
description: "Performance characteristics of the Kubetail stack: browser memory usage, kube-apiserver load, Cluster Agent throughput, and grep benchmarks."
---

import { Aside } from "@astrojs/starlight/components";

This page covers measured and expected performance characteristics for each part of the Kubetail stack. For a description of the components and how they fit together, see the [Architecture](/docs/concepts/architecture) page.

---

## Dashboard

### Dashboard UI

// TODO

#### Memory

Log records are held in a double-tailed array that supports O(1) append and prepend. Heap usage grows linearly with records held in memory.

**[Placeholder graph: Browser JS heap (MB) vs. records in memory — 1 k, 10 k, 50 k, 100 k. Measured with Chrome DevTools Memory profiler.]**

#### Network: WebSocket compression

WebSocket frames are compressed end-to-end (permessage-deflate). For typical log payloads this substantially reduces bandwidth between the Dashboard Server and the browser.

**[Placeholder graph: Compressed vs. uncompressed WebSocket bytes/s at 100, 1 k, 10 k log lines/s.]**

#### GraphQL caching (Apollo Client)

| Cache | Max entries |
|---|---|
| Query document cache | 1,000 |
| Automatic persisted query (APQ) cache | 100 |

### Dashboard server

// TODO

#### WebSocket connection overhead

Each browser session holds one persistent WebSocket connection. The server pre-allocates fixed buffers per connection.

| Setting | Default |
|---|---|
| Read buffer | 1,024 bytes |
| Write buffer | 1,024 bytes |
| Keep-alive ping interval | 10 s |

**[Placeholder graph: Dashboard Server memory (MB) vs. concurrent browser sessions (10, 50, 100, 500).]**

---

## Kubernetes API (default)

In the default mode every open log view generates long-lived HTTP streaming connections from the Dashboard Server to the kube-apiserver — one per container being tailed.

### kube-apiserver

The kube-apiserver proxies each log stream to the kubelet, so it bears the cost of every active stream:

- **CPU** — connection management and byte forwarding per stream
- **Memory** — one read buffer per active streaming connection
- **Network** — all log bytes travel kubelet → kube-apiserver → Dashboard Server (double-hop)

**[Placeholder graph: kube-apiserver CPU added by Kubetail vs. concurrent stream count (5, 20, 50, 100 pods) — baseline subtracted.]**

**[Placeholder graph: kube-apiserver memory added by Kubetail vs. concurrent stream count.]**

### kubelet

// TODO

---

## Kubetail API (optional)

### Cluster API

// TODO

#### gRPC fan-out latency

The Cluster API fans out to each relevant node in parallel. End-to-end query latency is bounded by the **slowest node**, not the sum.

**[Placeholder graph: P50 / P95 / P99 latency for `logRecordsFetch` vs. node count fanned out to (1, 5, 10, 20 nodes).]**

#### Concurrent stream overhead

**[Placeholder graph: Cluster API CPU (millicores) vs. concurrent log streams (1, 10, 50, 100).]**

**[Placeholder graph: Cluster API memory (MB) vs. concurrent log streams.]**

### Cluster Agent

The Cluster Agent is written in Rust and compiled with maximum release optimizations, giving it a small footprint relative to the log volume it can serve.

// TODO

#### Log streaming throughput

The agent is notified of new log lines via OS inotify events — no polling interval. New lines are read and forwarded over gRPC as soon as they are written.

**[Placeholder graph: Cluster Agent CPU (millicores) vs. log ingestion rate (lines/s) per node.]**

**[Placeholder graph: Cluster Agent memory (MB) vs. pods watched per node.]**

#### grep / search throughput

Text filtering uses the ripgrep `grep-searcher` crate. Patterns are compiled once per search request via `LazyLock`.

**[Placeholder graph: Grep throughput (MB/s) for simple substring, anchored regex, and complex regex — measured with criterion benchmarks in the `rgkl` crate.]**

---

## Scalability summary

| Dimension           | Kubernetes API mode                                       | Kubetail API mode                                       |
|---------------------|-----------------------------------------------------------|---------------------------------------------------------|
| kube-apiserver load | Auth checks, workload data, one HTTP stream per container | Auth checks and workload data only                      |
| Text filtering      | Post-transfer on Dashboard server (using Go)              | Pre-transfer on node (using Rust)                       |
| Concurrent streams  | kube-apiserver connection limits                          | inotify watch limits (thousands per process by default) |

---

## Resource requests and limits

Default Helm chart values for each component are listed below. Adjust based on observed usage.

**[Placeholder table: CPU requests/limits and memory requests/limits for Dashboard Server, Cluster API, and Cluster Agent — sourced from Helm chart values.yaml.]**

<Aside type="tip">
Start with the defaults and use the graphs above to identify the bottleneck in your environment before adjusting limits.
</Aside>
